{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and initialization of general parameters\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from config.info import AGES, RACES, GENDERS, COMBS_BASELINE\n",
    "from visualization.subgroup_distribution import plot_dist\n",
    "from dataprocess.dataloader import load_data\n",
    "from dataprocess.dataclass import Data\n",
    "from config.get_args import get_args\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Auto reload part\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the desired data set\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref(task, cancer):\n",
    "    # args\n",
    "    args = argparse.Namespace()\n",
    "    args.task = task\n",
    "    args.cancer = cancer\n",
    "    args = get_args(args = args)\n",
    "    print(args.task, args.cancer)\n",
    "    \n",
    "    # Load the ref\n",
    "    _, _, _, ref = load_data(**vars(args))\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cancer_classification', 'coad_read_FS']\n",
      "cancer_classification coad_read_FS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gav061/Documents/Intersectional-Fairness-on-Histopathological-images-classification/dataprocess/dataloader.py:34: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  nested_data = torch.nested.nested_tensor(tensors_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cancer_classification', 'coad_read_PM']\n",
      "cancer_classification coad_read_PM\n",
      "['cancer_classification', 'kich_kirc_FS']\n",
      "cancer_classification kich_kirc_FS\n",
      "['cancer_classification', 'kich_kirc_PM']\n",
      "cancer_classification kich_kirc_PM\n",
      "['cancer_classification', 'kich_kirp_FS']\n",
      "cancer_classification kich_kirp_FS\n",
      "['cancer_classification', 'kich_kirp_PM']\n",
      "cancer_classification kich_kirp_PM\n",
      "['cancer_classification', 'kirc_kirp_FS']\n",
      "cancer_classification kirc_kirp_FS\n",
      "['cancer_classification', 'kirc_kirp_PM']\n",
      "cancer_classification kirc_kirp_PM\n",
      "['cancer_classification', 'luad_lusc_FS']\n",
      "cancer_classification luad_lusc_FS\n",
      "['cancer_classification', 'luad_lusc_PM']\n",
      "cancer_classification luad_lusc_PM\n",
      "['tumor_detection', 'brca']\n",
      "tumor_detection brca\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m cancer \u001b[38;5;241m=\u001b[39m comb[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get the references \u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m ref \u001b[38;5;241m=\u001b[39m get_ref(task, cancer)\n\u001b[1;32m     18\u001b[0m ref[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m     19\u001b[0m ref[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcancer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cancer\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mget_ref\u001b[0;34m(task, cancer)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(args\u001b[38;5;241m.\u001b[39mtask, args\u001b[38;5;241m.\u001b[39mcancer)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the ref\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m _, _, _, ref \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mvars\u001b[39m(args))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ref\n",
      "File \u001b[0;32m~/Documents/Intersectional-Fairness-on-Histopathological-images-classification/dataprocess/dataloader.py:25\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m protected_attributes_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprotected_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m])), dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(references)):\n\u001b[0;32m---> 25\u001b[0m     tensor_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(references\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39miloc[idx])\n\u001b[1;32m     26\u001b[0m     response \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([response, torch\u001b[38;5;241m.\u001b[39mTensor([references\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39miloc[idx]])])\n\u001b[1;32m     27\u001b[0m     current_protected_att_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;28mlist\u001b[39m(references[kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprotected_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39miloc[idx])])\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/site-packages/torch/serialization.py:987\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    992\u001b[0m         overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/site-packages/torch/serialization.py:121\u001b[0m, in \u001b[0;36m_is_zipfile\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    118\u001b[0m read_bytes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    119\u001b[0m start \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m--> 121\u001b[0m byte \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m byte \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    123\u001b[0m     read_bytes\u001b[38;5;241m.\u001b[39mappend(byte)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build the data frame\n",
    "cols = ['task', 'cancer', \n",
    "        'label', 'age_', \n",
    "        'race_', 'gender_', \n",
    "        'subj', 'siteID']\n",
    "df = pd.DataFrame(columns = cols)\n",
    "\n",
    "for comb in COMBS_BASELINE:\n",
    "    # Track\n",
    "    print(comb)\n",
    "    \n",
    "    # Extract combinations\n",
    "    task = comb[0]\n",
    "    cancer = comb[1]\n",
    "    \n",
    "    # Get the references \n",
    "    ref = get_ref(task, cancer)\n",
    "    ref['task'] = task\n",
    "    ref['cancer'] = cancer\n",
    "    \n",
    "    # Update the main dataframe\n",
    "    df = pd.concat([df, ref[cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_classification luad_lusc_PM\n"
     ]
    }
   ],
   "source": [
    "td = get_ref('cancer_classification', 'luad_lusc_PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_  race_  gender_\n",
       "7     1      1          164\n",
       "6     1      1          160\n",
       "7     1      0          130\n",
       "6     1      0          114\n",
       "5     1      1           66\n",
       "             0           46\n",
       "8     1      1           41\n",
       "             0           22\n",
       "4     1      1           20\n",
       "             0           17\n",
       "6     2      1            3\n",
       "7     2      1            3\n",
       "3     1      0            3\n",
       "6     2      0            2\n",
       "7     2      0            2\n",
       "4     2      1            2\n",
       "3     1      1            1\n",
       "5     2      1            1\n",
       "4     2      0            1\n",
       "8     2      0            1\n",
       "             1            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td[['age_', 'race_', 'gender_']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
